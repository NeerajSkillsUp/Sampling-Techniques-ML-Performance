{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QQtWsVDbEiyP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7500be-20c5-4baa-8614-5c4d001d3842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (772, 31)\n",
            "\n",
            "First few rows:\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      1  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Class Distribution:\n",
            "Class\n",
            "0    763\n",
            "1      9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class Distribution Percentage:\n",
            "Class\n",
            "0    98.834197\n",
            "1     1.165803\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "!pip install -q imbalanced-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler,TomekLinks\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "print(\"\\nClass Distribution:\")\n",
        "print(df['Class'].value_counts())\n",
        "print(\"\\nClass Distribution Percentage:\")\n",
        "print(df['Class'].value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "print(\"\\nImbalance Ratio:\", y.value_counts()[0] / y.value_counts()[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMtl1XDHFSsR",
        "outputId": "3ee07e24-ee2e-47b6-b8bd-8c421f1bdf4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Imbalance Ratio: 84.77777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced,y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nBalanced class distribution:\")\n",
        "print(y_balanced.value_counts())\n",
        "print(\"\\nBalanced dataset shape:\", X_balanced.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRbpLC5PFVGB",
        "outputId": "16039ddc-0f01-4536-81b7-ad3803fe5aa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Balanced class distribution:\n",
            "Class\n",
            "0    763\n",
            "1    763\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Balanced dataset shape: (1526, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate sample size using formula\n",
        "# Sample size formula: n = (Z^2 * p * (1-p)) / E^2\n",
        "# Where: Z = 1.96 (for 95% confidence), p = 0.5, E = 0.05 (margin of error)\n",
        "\n",
        "import math\n",
        "Z = 1.96  # 95% confidence level\n",
        "p = 0.5   # proportion (maximum variability)\n",
        "E = 0.05  # margin of error\n",
        "\n",
        "sample_size = int((Z**2 * p * (1-p)) / E**2)\n",
        "print(f\"Calculated sample size: {sample_size}\")\n",
        "\n",
        "# Adjust if sample size is larger than our dataset\n",
        "if sample_size > len(X_balanced):\n",
        "    sample_size = int(len(X_balanced) * 0.3)  # Use 30% of balanced data\n",
        "\n",
        "print(f\"Sample size to be used: {sample_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjLo0svUFYth",
        "outputId": "903a101a-8acd-4f32-c93c-b3243e284409"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculated sample size: 384\n",
            "Sample size to be used: 384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 5 different samples using different sampling techniques\n",
        "\n",
        "# Sampling Technique 1: Simple Random Sampling\n",
        "def simple_random_sampling(X, y, n):\n",
        "    indices = np.random.choice(len(X), size=n, replace=False)\n",
        "    return X.iloc[indices], y.iloc[indices]\n",
        "\n",
        "# Sampling Technique 2: Systematic Sampling\n",
        "def systematic_sampling(X, y, n):\n",
        "    k = len(X) // n\n",
        "    start = np.random.randint(0, k)\n",
        "    indices = np.arange(start, len(X), k)[:n]\n",
        "    return X.iloc[indices], y.iloc[indices]\n",
        "\n",
        "# Sampling Technique 3: Stratified Sampling\n",
        "def stratified_sampling(X, y, n):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_sample, _, y_sample, _ = train_test_split(X, y, train_size=n, stratify=y, random_state=42)\n",
        "    return X_sample, y_sample\n",
        "\n",
        "# Sampling Technique 4: Cluster Sampling\n",
        "def cluster_sampling(X, y, n):\n",
        "    from sklearn.cluster import KMeans\n",
        "    n_clusters = 5\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    clusters = kmeans.fit_predict(X)\n",
        "\n",
        "    samples_per_cluster = n // n_clusters\n",
        "    indices = []\n",
        "    for i in range(n_clusters):\n",
        "        cluster_indices = np.where(clusters == i)[0]\n",
        "        if len(cluster_indices) > 0:\n",
        "            selected = np.random.choice(cluster_indices,\n",
        "                                       size=min(samples_per_cluster, len(cluster_indices)),\n",
        "                                       replace=False)\n",
        "            indices.extend(selected)\n",
        "\n",
        "    indices = indices[:n]\n",
        "    return X.iloc[indices], y.iloc[indices]\n",
        "\n",
        "# Sampling Technique 5: Bootstrap Sampling (with replacement)\n",
        "def bootstrap_sampling(X, y, n):\n",
        "    indices = np.random.choice(len(X), size=n, replace=True)\n",
        "    return X.iloc[indices], y.iloc[indices]\n",
        "\n",
        "# Create 5 samples\n",
        "print(\"Creating 5 different samples...\\n\")\n",
        "\n",
        "samples = {}\n",
        "samples['Sample1_SimpleRandom'] = simple_random_sampling(X_balanced, y_balanced, sample_size)\n",
        "samples['Sample2_Systematic'] = systematic_sampling(X_balanced, y_balanced, sample_size)\n",
        "samples['Sample3_Stratified'] = stratified_sampling(X_balanced, y_balanced, sample_size)\n",
        "samples['Sample4_Cluster'] = cluster_sampling(X_balanced, y_balanced, sample_size)\n",
        "samples['Sample5_Bootstrap'] = bootstrap_sampling(X_balanced, y_balanced, sample_size)\n",
        "\n",
        "for name, (X_sample, y_sample) in samples.items():\n",
        "    print(f\"{name}: Shape = {X_sample.shape}, Class distribution:\")\n",
        "    print(pd.Series(y_sample).value_counts())\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtfBabzGFbjp",
        "outputId": "79f9fe04-d598-4d53-b360-b5fad05e14de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating 5 different samples...\n",
            "\n",
            "Sample1_SimpleRandom: Shape = (384, 30), Class distribution:\n",
            "Class\n",
            "0    197\n",
            "1    187\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample2_Systematic: Shape = (384, 30), Class distribution:\n",
            "Class\n",
            "0    255\n",
            "1    129\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample3_Stratified: Shape = (384, 30), Class distribution:\n",
            "Class\n",
            "0    192\n",
            "1    192\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample4_Cluster: Shape = (303, 30), Class distribution:\n",
            "Class\n",
            "1    153\n",
            "0    150\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample5_Bootstrap: Shape = (384, 30), Class distribution:\n",
            "Class\n",
            "1    195\n",
            "0    189\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define 5 ML Models\n",
        "\n",
        "models = {\n",
        "    'M1_LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'M2_DecisionTree': DecisionTreeClassifier(random_state=42),\n",
        "    'M3_RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'M4_SVM': SVC(kernel='rbf', random_state=42),\n",
        "    'M5_GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "print(\"Models defined:\")\n",
        "for model_name in models.keys():\n",
        "    print(f\"  - {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Jf6H2gFfjj",
        "outputId": "cd7c5832-d599-43b7-979c-006961a85fb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models defined:\n",
            "  - M1_LogisticRegression\n",
            "  - M2_DecisionTree\n",
            "  - M3_RandomForest\n",
            "  - M4_SVM\n",
            "  - M5_GradientBoosting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate all models on all samples\n",
        "\n",
        "results = {}\n",
        "print(\"Training and evaluating models...\\n\")\n",
        "for sample_name, (X_sample, y_sample) in samples.items():\n",
        "    print(f\"\\nProcessing {sample_name}...\")\n",
        "    results[sample_name] = {}\n",
        "    # Split into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.3, random_state=42, stratify=y_sample)\n",
        "    for model_name, model in models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "        results[sample_name][model_name] = accuracy\n",
        "\n",
        "        print(f\"  {model_name}: {accuracy:.2f}%\")\n",
        "\n",
        "print(\"\\nTraining complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3PtKgsiFiVJ",
        "outputId": "8d786658-5e3a-444e-b5b4-0a818ea3f31e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and evaluating models...\n",
            "\n",
            "\n",
            "Processing Sample1_SimpleRandom...\n",
            "  M1_LogisticRegression: 91.38%\n",
            "  M2_DecisionTree: 92.24%\n",
            "  M3_RandomForest: 99.14%\n",
            "  M4_SVM: 55.17%\n",
            "  M5_GradientBoosting: 96.55%\n",
            "\n",
            "Processing Sample2_Systematic...\n",
            "  M1_LogisticRegression: 88.79%\n",
            "  M2_DecisionTree: 90.52%\n",
            "  M3_RandomForest: 99.14%\n",
            "  M4_SVM: 67.24%\n",
            "  M5_GradientBoosting: 98.28%\n",
            "\n",
            "Processing Sample3_Stratified...\n",
            "  M1_LogisticRegression: 91.38%\n",
            "  M2_DecisionTree: 91.38%\n",
            "  M3_RandomForest: 98.28%\n",
            "  M4_SVM: 68.10%\n",
            "  M5_GradientBoosting: 96.55%\n",
            "\n",
            "Processing Sample4_Cluster...\n",
            "  M1_LogisticRegression: 92.31%\n",
            "  M2_DecisionTree: 92.31%\n",
            "  M3_RandomForest: 98.90%\n",
            "  M4_SVM: 67.03%\n",
            "  M5_GradientBoosting: 95.60%\n",
            "\n",
            "Processing Sample5_Bootstrap...\n",
            "  M1_LogisticRegression: 92.24%\n",
            "  M2_DecisionTree: 93.10%\n",
            "  M3_RandomForest: 99.14%\n",
            "  M4_SVM: 67.24%\n",
            "  M5_GradientBoosting: 97.41%\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create results table\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.columns = ['M1', 'M2', 'M3', 'M4', 'M5']\n",
        "results_df.index = ['Sampling1', 'Sampling2', 'Sampling3', 'Sampling4', 'Sampling5']\n",
        "results_df = results_df.round(2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTS TABLE: Accuracy (%) of Models on Different Samples\")\n",
        "print(\"=\"*60)\n",
        "print(results_df)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhiwOQIUFlHA",
        "outputId": "376f29af-6845-46c8-a6a0-9d702ac507eb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RESULTS TABLE: Accuracy (%) of Models on Different Samples\n",
            "============================================================\n",
            "              M1     M2     M3     M4     M5\n",
            "Sampling1  91.38  92.24  99.14  55.17  96.55\n",
            "Sampling2  88.79  90.52  99.14  67.24  98.28\n",
            "Sampling3  91.38  91.38  98.28  68.10  96.55\n",
            "Sampling4  92.31  92.31  98.90  67.03  95.60\n",
            "Sampling5  92.24  93.10  99.14  67.24  97.41\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best sampling technique for each model\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BEST SAMPLING TECHNIQUE FOR EACH MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for model in results_df.columns:\n",
        "    best_sampling = results_df[model].idxmax()\n",
        "    best_accuracy = results_df[model].max()\n",
        "    print(f\"{model}: {best_sampling} with accuracy = {best_accuracy:.2f}%\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o32r-4byFn3x",
        "outputId": "ac8efee2-40e3-44aa-c866-9150257fd4d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BEST SAMPLING TECHNIQUE FOR EACH MODEL\n",
            "============================================================\n",
            "M1: Sampling4 with accuracy = 92.31%\n",
            "M2: Sampling5 with accuracy = 93.10%\n",
            "M3: Sampling1 with accuracy = 99.14%\n",
            "M4: Sampling3 with accuracy = 68.10%\n",
            "M5: Sampling2 with accuracy = 98.28%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find best model for each sampling technique\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"BEST MODEL FOR EACH SAMPLING TECHNIQUE\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for sampling in results_df.index:\n",
        "    best_model = results_df.loc[sampling].idxmax()\n",
        "    best_accuracy = results_df.loc[sampling].max()\n",
        "    print(f\"{sampling}: {best_model} with accuracy = {best_accuracy:.2f}%\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LQ680vCFqKj",
        "outputId": "fae616af-deb6-431e-bb26-47774ea5a149"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "BEST MODEL FOR EACH SAMPLING TECHNIQUE\n",
            "============================================================\n",
            "Sampling1: M3 with accuracy = 99.14%\n",
            "Sampling2: M3 with accuracy = 99.14%\n",
            "Sampling3: M3 with accuracy = 98.28%\n",
            "Sampling4: M3 with accuracy = 98.90%\n",
            "Sampling5: M3 with accuracy = 99.14%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Overall best combination\n",
        "\n",
        "best_overall = results_df.max().max()\n",
        "best_model_overall = results_df.max().idxmax()\n",
        "best_sampling_overall = results_df[best_model_overall].idxmax()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"OVERALL BEST COMBINATION\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Best Model: {best_model_overall}\")\n",
        "print(f\"Best Sampling: {best_sampling_overall}\")\n",
        "print(f\"Accuracy: {best_overall:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIF0kvamFt7R",
        "outputId": "e404b69a-7890-41a0-fa97-8983f9485de4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "OVERALL BEST COMBINATION\n",
            "============================================================\n",
            "Best Model: M3\n",
            "Best Sampling: Sampling1\n",
            "Accuracy: 99.14%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results table\n",
        "results_df.to_csv('sampling_results.csv')\n",
        "print(\"\\nResults saved to 'sampling_results.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5yq1rUvF38a",
        "outputId": "f57210a4-82f5-4fcf-e2a3-322fb0722f3b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to 'sampling_results.csv'\n"
          ]
        }
      ]
    }
  ]
}